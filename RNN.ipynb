{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1530d307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Last summer I had an appointment to get new ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Friendly staff, same starbucks fair you get an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The food is good. Unfortunately the service is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Even when we didn't have a car Filene's Baseme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Picture Billy Joel's \\\"Piano Man\\\" DOUBLED mix...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message\n",
       "0         1  Last summer I had an appointment to get new ti...\n",
       "1         2  Friendly staff, same starbucks fair you get an...\n",
       "2         1  The food is good. Unfortunately the service is...\n",
       "3         2  Even when we didn't have a car Filene's Baseme...\n",
       "4         2  Picture Billy Joel's \\\"Piano Man\\\" DOUBLED mix..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75869b1",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce632456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40aa084",
   "metadata": {},
   "source": [
    "# Tokenize message and remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7e1c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['tokenized_text'] = df['Message'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b7309ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Last summer I had an appointment to get new ti...</td>\n",
       "      <td>[Last, summer, I, had, an, appointment, to, ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Friendly staff, same starbucks fair you get an...</td>\n",
       "      <td>[Friendly, staff, ,, same, starbucks, fair, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The food is good. Unfortunately the service is...</td>\n",
       "      <td>[The, food, is, good, ., Unfortunately, the, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Even when we didn't have a car Filene's Baseme...</td>\n",
       "      <td>[Even, when, we, did, n't, have, a, car, Filen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Picture Billy Joel's \\\"Piano Man\\\" DOUBLED mix...</td>\n",
       "      <td>[Picture, Billy, Joel, 's, \\, '', Piano, Man\\,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message  \\\n",
       "0         1  Last summer I had an appointment to get new ti...   \n",
       "1         2  Friendly staff, same starbucks fair you get an...   \n",
       "2         1  The food is good. Unfortunately the service is...   \n",
       "3         2  Even when we didn't have a car Filene's Baseme...   \n",
       "4         2  Picture Billy Joel's \\\"Piano Man\\\" DOUBLED mix...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [Last, summer, I, had, an, appointment, to, ge...  \n",
       "1  [Friendly, staff, ,, same, starbucks, fair, yo...  \n",
       "2  [The, food, is, good, ., Unfortunately, the, s...  \n",
       "3  [Even, when, we, did, n't, have, a, car, Filen...  \n",
       "4  [Picture, Billy, Joel, 's, \\, '', Piano, Man\\,...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bedc530",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4d84a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c4dc4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(txt_tokenized):\n",
    "    tokens_without_sw = [word for word in txt_tokenized if not word in stopwords]\n",
    "    return tokens_without_sw\n",
    "\n",
    "df['message_no_sw']=df['tokenized_text'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccb6c219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Last',\n",
       " 'summer',\n",
       " 'I',\n",
       " 'appointment',\n",
       " 'get',\n",
       " 'new',\n",
       " 'tires',\n",
       " 'wait',\n",
       " 'super',\n",
       " 'long',\n",
       " 'time',\n",
       " '.',\n",
       " 'I',\n",
       " 'also',\n",
       " 'went',\n",
       " 'week',\n",
       " 'fix',\n",
       " 'minor',\n",
       " 'problem',\n",
       " 'tire',\n",
       " 'put',\n",
       " '.',\n",
       " 'They',\n",
       " '\\\\',\n",
       " \"''\",\n",
       " 'fixed\\\\',\n",
       " \"''\",\n",
       " 'free',\n",
       " ',',\n",
       " 'next',\n",
       " 'morning',\n",
       " 'I',\n",
       " 'issue',\n",
       " '.',\n",
       " 'I',\n",
       " 'called',\n",
       " 'complain',\n",
       " ',',\n",
       " '\\\\',\n",
       " \"''\",\n",
       " 'manager\\\\',\n",
       " \"''\",\n",
       " \"n't\",\n",
       " 'even',\n",
       " 'apologize',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " 'So',\n",
       " 'frustrated',\n",
       " '.',\n",
       " 'Never',\n",
       " 'going',\n",
       " 'back',\n",
       " '.',\n",
       " 'They',\n",
       " 'seem',\n",
       " 'overpriced',\n",
       " ',',\n",
       " '.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message_no_sw'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671cfb5e",
   "metadata": {},
   "source": [
    "# Encode the words and pad the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "267e17c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 113,   3, 638,\n",
       "        15,  95,  88, 273, 124,  19,   1,   3,  38,  45, 332, 708, 394,\n",
       "       206,   1,  33,  25,   8,   8, 209,   2, 108, 518,   3, 661,   1,\n",
       "         3, 170,   2,  25,   8,   8,   5,  31,   4,   4,   4, 104,   1,\n",
       "        41,  57,  24,   1,  33, 475, 616,   2,   1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=1000, split=\" \")\n",
    "tokenizer.fit_on_texts(df['message_no_sw'].values)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(df['message_no_sw'].values)\n",
    "X = pad_sequences(X) # padding our text vector so they all have the same length\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a52fa26e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [1 0]\n",
      "2 [0 1]\n",
      "1 [1 0]\n",
      "2 [0 1]\n",
      "2 [0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(df['Category']).values\n",
    "[print(df['Category'][i],y[i]) for i in range(0,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa6132",
   "metadata": {},
   "source": [
    "# Create a RNN with LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a66ed272",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64, input_length=1000))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 2 units.\n",
    "model.add(layers.Dense(2))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8dc492f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 64)          64000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 163,074\n",
      "Trainable params: 163,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f70507",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af7e64c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80fff398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1000) for input Tensor(\"embedding_1_input:0\", shape=(None, 1000), dtype=float32), but it was called on an input with incompatible shape (None, 607).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1000) for input Tensor(\"embedding_1_input:0\", shape=(None, 1000), dtype=float32), but it was called on an input with incompatible shape (None, 607).\n",
      "950/950 [==============================] - 283s 298ms/step - loss: nan - accuracy: 0.5000\n",
      "Epoch 2/3\n",
      "950/950 [==============================] - 777s 818ms/step - loss: nan - accuracy: 0.5000\n",
      "Epoch 3/3\n",
      "950/950 [==============================] - 2157s 2s/step - loss: nan - accuracy: 0.5001\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 3\n",
    "\n",
    "history=model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b243db8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1000) for input Tensor(\"embedding_1_input:0\", shape=(None, 1000), dtype=float32), but it was called on an input with incompatible shape (None, 607).\n",
      "238/238 [==============================] - 0s 981us/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "Test Loss: 0.0\n",
      "Test Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b647ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:demo2] *",
   "language": "python",
   "name": "conda-env-demo2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
